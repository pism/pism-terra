{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d539dab6-c4b2-4fc7-aa50-49cc2e485f2c",
   "metadata": {},
   "source": [
    "# PISM TERRA for AGU 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be45f012-7926-4cd3-8cd2-8c3317cdd633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import matplotlib.pylab as plt\n",
    "import re\n",
    "from functools import partial\n",
    "from collections import OrderedDict, defaultdict\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import warnings\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from dateutil.parser import parse as date_parser\n",
    "import pint_xarray\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.distributed import Client, progress\n",
    "import hyp3_sdk as sdk\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from matplotlib import cm, colors\n",
    "import cmcrameri.cm as cmc\n",
    "\n",
    "from pism_terra.processing import preprocess_config, normalize_cumulative_variables, standardize_variable_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76fe5ee-6442-4c70-9893-c91bf16cb7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick(files, pattern):\n",
    "    for f in files:\n",
    "        if pattern in Path(f).name:\n",
    "            return f\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29298082-fc5b-4dbf-b221-b0fc0c7cc062",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fs = s3fs.S3FileSystem(anon=True)  # or anon=True if public\n",
    "\n",
    "PISM_CLOUD_BUCKET = 'hyp3-pism-cloud-test-contentbucket-zs9dctrqrlvx'\n",
    "\n",
    "campaign = \"era5_ec2\"\n",
    "\n",
    "user_id = \"jhkennedy\"\n",
    "RGI_IDS = [\n",
    "    'RGI2000-v7.0-C-01-03383',\n",
    "    'RGI2000-v7.0-C-01-03102',\n",
    "    'RGI2000-v7.0-C-01-01407',\n",
    "    'RGI2000-v7.0-C-01-08332',\n",
    "    'RGI2000-v7.0-C-01-14907',\n",
    "    'RGI2000-v7.0-C-01-16106',\n",
    "    'RGI2000-v7.0-C-01-14978',\n",
    "    'RGI2000-v7.0-C-01-14612',\n",
    "    'RGI2000-v7.0-C-01-04024',\n",
    "    'RGI2000-v7.0-C-01-12784',\n",
    "    'RGI2000-v7.0-C-01-04374',\n",
    "    'RGI2000-v7.0-C-01-11818',\n",
    "    'RGI2000-v7.0-C-01-08012',\n",
    "    'RGI2000-v7.0-C-01-09429',\n",
    "    'RGI2000-v7.0-C-01-16008',\n",
    "    'RGI2000-v7.0-C-01-08153',\n",
    "    'RGI2000-v7.0-C-01-03718',\n",
    "    'RGI2000-v7.0-C-01-06260',\n",
    "    'RGI2000-v7.0-C-01-05881',\n",
    "    'RGI2000-v7.0-C-01-04928',\n",
    "    'RGI2000-v7.0-C-01-05334',\n",
    "    'RGI2000-v7.0-C-01-14209',\n",
    "    'RGI2000-v7.0-C-01-13574',\n",
    "    'RGI2000-v7.0-C-01-02832',\n",
    "    'RGI2000-v7.0-C-01-07967',\n",
    "    'RGI2000-v7.0-C-01-10901',\n",
    "    'RGI2000-v7.0-C-01-00810',\n",
    "    'RGI2000-v7.0-C-01-05069',\n",
    "    'RGI2000-v7.0-C-01-04819',\n",
    "    'RGI2000-v7.0-C-01-03017',\n",
    "    'RGI2000-v7.0-C-01-07018']\n",
    "\n",
    "JOB_NAMES = [rgi_id + \"_\" + campaign for rgi_id in RGI_IDS]\n",
    "\n",
    "hyp3 = sdk.HyP3('https://pism-cloud-test.asf.alaska.edu')\n",
    "jobs = sdk.Batch()\n",
    "for job_name in JOB_NAMES:\n",
    "    jobs += hyp3.find_jobs(name=job_name, user_id=user_id, job_type='PISM_TERRA_EXECUTE', start=date_parser('2025-12-11'))\n",
    "\n",
    "s3_ids = {}\n",
    "jobs_succeeded = 0\n",
    "jobs_failed = 0\n",
    "jobs_running = 0\n",
    "jobs_pending = 0\n",
    "for job in jobs:\n",
    "    if job.job_type == 'PISM_TERRA_EXECUTE':\n",
    "        rgi_id = job.name.split(\"_\" + campaign)[0]\n",
    "        job_id = job.job_id\n",
    "        if job.status_code == \"SUCCEEDED\":\n",
    "            s3_id = f's3://{PISM_CLOUD_BUCKET}/{job.job_id}'\n",
    "            s3_ids[job_id] = {\"rgi_id\": rgi_id, \"s3_id\": s3_id}\n",
    "            jobs_succeeded += 1\n",
    "        elif job.status_code == \"FAILED\":\n",
    "            jobs_failed += 1\n",
    "        elif job.status_code == \"RUNNING\":\n",
    "            jobs_running += 1\n",
    "        elif job.status_code == \"PENDING\":\n",
    "            jobs_pending += 1\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "print(f\"PENDING: {jobs_pending}\")\n",
    "print(f\"RUNNING: {jobs_running}\")\n",
    "print(f\"SUCCEEDED: {jobs_succeeded}\")\n",
    "print(f\"FAILED: {jobs_failed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d6db3c-4eb6-406c-b4dd-eef08c370686",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "client = Client()  # or connect to your scheduler\n",
    "print(f\"Open client in browser: {client.dashboard_link}\")\n",
    "\n",
    "def pick(files, pattern):\n",
    "    for f in files:\n",
    "        if pattern in Path(f).name:\n",
    "            return f\n",
    "    return None\n",
    "\n",
    "def list_and_pick(job_id, s3_id, rgi_id, anon=True):\n",
    "    \"\"\"\n",
    "    List prefix on S3 and pick scalar + spatial files.\n",
    "    Returns (job_id, scalar_dict_or_None, spatial_dict_or_None).\n",
    "    \"\"\"\n",
    "    fs = s3fs.S3FileSystem(anon=anon)  # make a fresh FS on the worker\n",
    "    prefix = f\"{s3_id}/{rgi_id}/output/spatial/\"\n",
    "    files = fs.ls(prefix)\n",
    "\n",
    "    spatial_file = pick(files, \"clipped_spatial_\")\n",
    "    scalar_file  = pick(files, \"fldsum_spatial_\")\n",
    "\n",
    "    scalar_entry = None\n",
    "    spatial_entry = None\n",
    "\n",
    "    if scalar_file is not None:\n",
    "        scalar_entry = {\"rgi_id\": rgi_id, \"url\": f\"s3://{scalar_file}\"}\n",
    "    if spatial_file is not None:\n",
    "        spatial_entry = {\"rgi_id\": rgi_id, \"url\": f\"s3://{spatial_file}\"}\n",
    "\n",
    "    return job_id, scalar_entry, spatial_entry\n",
    "\n",
    "\n",
    "# ---- submit tasks ----\n",
    "futures = []\n",
    "for job_id, meta in s3_ids.items():\n",
    "    futures.append(\n",
    "        client.submit(list_and_pick, job_id, meta[\"s3_id\"], meta[\"rgi_id\"], True)\n",
    "    )\n",
    "\n",
    "progress(futures)\n",
    "\n",
    "# ---- gather and assemble ----\n",
    "scalar_dict = {}\n",
    "spatial_dict = {}\n",
    "\n",
    "for job_id, scalar_entry, spatial_entry in client.gather(futures):\n",
    "    if scalar_entry is not None:\n",
    "        scalar_dict[job_id] = scalar_entry\n",
    "    if spatial_entry is not None:\n",
    "        spatial_dict[job_id] = spatial_entry\n",
    "\n",
    "scalar_files  = [v[\"url\"] for v in scalar_dict.values()]\n",
    "spatial_files = [v[\"url\"] for v in spatial_dict.values()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51403b16-9cfe-405a-a98b-6fdac369eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rgi_p = Path(\"/Users/andy/Google Drive/My Drive/Projects/terra/data/rgi/\")\n",
    "\n",
    "rgi = gpd.read_file(\"../data/rgi/rgi.gpkg\")\n",
    "rgi_ak = rgi[rgi[\"o1region\"] == \"01\"]\n",
    "\n",
    "processed_glaciers_ids = np.unique([v[\"rgi_id\"] for v in scalar_dict.values()])\n",
    "ak_total_area = rgi_ak[\"area_km2\"].sum()\n",
    "ak_processed_glaciers = rgi_ak[rgi_ak[\"rgi_id\"].isin(processed_glaciers_ids)] \n",
    "ak_processed_area = ak_processed_glaciers[\"area_km2\"].sum()\n",
    "ak_processed_glaciers.to_file(rgi_p / \"ak_processed_glaciers.gpkg\")\n",
    "ak_processed_area_percent = ak_processed_area / ak_total_area * 100\n",
    "print(ak_processed_area_percent)\n",
    "\n",
    "n_processed_glaciers = len(processed_glaciers_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d1c7c4-0063-45c9-9ef1-eff5dd81274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mb_vars = {\"ice_mass\": \"cumulative_mass_balance\",\n",
    " \"tendency_of_ice_mass_due_to_surface_mass_flux\": \"surface_mass_balance\",\n",
    " \"tendency_of_ice_mass_due_to_discharge\": \"ice_discharge\",\n",
    " \"tendency_of_ice_mass\": \"mass_balance\"}\n",
    "\n",
    "scalar_ds = xr.open_mfdataset(scalar_files, preprocess=preprocess_config, parallel=True, chunks=\"auto\", engine=\"h5netcdf\").sel({\"time\": slice(\"1980\", \"2025\")})\n",
    "scalar_ds = standardize_variable_names(scalar_ds, mb_vars)\n",
    "scalar_ds = normalize_cumulative_variables(scalar_ds, \"cumulative_mass_balance\", reference_date=\"1980-01-01\")\n",
    "scalar_ds = scalar_ds[list(mb_vars.values())].pint.quantify()\n",
    "scalar_ds[\"cumulative_mass_balance\"] = scalar_ds[\"cumulative_mass_balance\"].pint.to(\"Gt\")\n",
    "\n",
    "all_glaciers = scalar_ds.sum(dim=\"rgi_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85b2612-069a-4298-8554-a9dfc9dbf1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = [0.05, 0.16, 0.50, 0.84, 0.95]\n",
    "percentile_range_90 = (percentiles[-1] - percentiles[0]) * 100\n",
    "percentile_range_68 = (percentiles[-2] - percentiles[1]) * 100\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", r\"All-NaN (slice|axis) encountered\")\n",
    "    all_quantiles = {}\n",
    "    for q in percentiles:\n",
    "        all_quantiles[q] = all_glaciers.quantile(q, dim=\"exp_id\", skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012ca8e9-75c7-4eb8-9e61-e329a77a6e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 8\n",
    "sim_alpha = 0.6\n",
    "sim_cmap = [\"#216778\",  \"#84cedc\", \"#ffffff\", \"#CC6677\", \"#882255\"]\n",
    "obs_alpha = 1.0\n",
    "obs_cmap = [\"0.8\", \"0.9\"]\n",
    "hist_cmap = [\"#a6cee3\", \"#1f78b4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc8c678-d808-4923-b5d7-465db81ba970",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_median = True\n",
    "p_var = \"cumulative_mass_balance\"\n",
    "p = Path(\"/Users/andy/Google Drive/My Drive/Projects/terra/figures/\")\n",
    "figsize = (6.2, 6.2 * 9 / 16)\n",
    "x_lim = [1980, 2025]\n",
    "rcparams_white = {\n",
    "    \"axes.linewidth\": 0.5,\n",
    "    \"axes.edgecolor\": \"white\",\n",
    "    \"xtick.major.size\": 2.0,\n",
    "    \"xtick.major.width\": 0.25,\n",
    "    \"ytick.major.size\": 2.0,\n",
    "    \"ytick.major.width\": 0.25,\n",
    "    \"hatch.linewidth\": 0.25,\n",
    "    'font.weight': \"bold\",\n",
    "    \"font.size\": fontsize,\n",
    "    'axes.labelweight': \"bold\",\n",
    "    'text.color': \"white\",\n",
    "    'axes.labelcolor': \"white\",\n",
    "    'xtick.color': \"white\",\n",
    "    'ytick.color': \"white\",\n",
    "}\n",
    "\n",
    "with mpl.rc_context(rcparams_white):\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    all_cis = []\n",
    "    all_ci = ax.fill_between(\n",
    "        all_quantiles[0.5].time,\n",
    "        all_quantiles[percentiles[0]][p_var],\n",
    "        all_quantiles[percentiles[-1]][p_var],\n",
    "        alpha=sim_alpha,\n",
    "        color=sim_cmap[0],\n",
    "        lw=0,\n",
    "        label=f\"\"\"{percentile_range_90:.0f}% c.i.\"\"\",\n",
    "    )\n",
    "    all_cis.append(all_ci)\n",
    "    all_ci = ax.fill_between(\n",
    "        all_quantiles[0.5].time,\n",
    "        all_quantiles[percentiles[1]][p_var],\n",
    "        all_quantiles[percentiles[-2]][p_var],\n",
    "        alpha=sim_alpha,\n",
    "        color=sim_cmap[1],\n",
    "        lw=0,\n",
    "        label=f\"\"\"{percentile_range_68:.0f}% c.i.\"\"\",\n",
    "    )\n",
    "    all_cis.append(all_ci)\n",
    "    \n",
    "    if add_median:\n",
    "        all_quantiles[percentiles[0]][p_var].plot(\n",
    "            color=sim_cmap[2],\n",
    "            add_legend=False,\n",
    "            ax=ax,\n",
    "            lw=0.5,\n",
    "            ls=\"solid\",\n",
    "        )\n",
    "        all_quantiles[percentiles[1]][p_var].plot(\n",
    "            color=sim_cmap[2],\n",
    "            add_legend=False,\n",
    "            ax=ax,\n",
    "            lw=0.5,\n",
    "            ls=\"solid\",\n",
    "        )\n",
    "        h  = all_quantiles[0.5][p_var].plot(\n",
    "            color=sim_cmap[2],\n",
    "            add_legend=False,\n",
    "            ax=ax,\n",
    "            lw=1,\n",
    "            ls=\"solid\",\n",
    "            label=\"Median\"\n",
    "        )\n",
    "        all_cis.append(h[0])\n",
    "        all_quantiles[percentiles[-2]][p_var].plot(\n",
    "            color=sim_cmap[2],\n",
    "            add_legend=False,\n",
    "            ax=ax,\n",
    "            lw=0.5,\n",
    "            ls=\"solid\",\n",
    "        )\n",
    "        all_quantiles[percentiles[-1]][p_var].plot(\n",
    "            color=sim_cmap[2],\n",
    "            add_legend=False,\n",
    "            ax=ax,\n",
    "            lw=0.5,\n",
    "            ls=\"solid\",\n",
    "        )\n",
    "    l = ax.legend(handles=all_cis[::-1], loc=\"lower left\")\n",
    "    l.get_frame().set_linewidth(0.0)\n",
    "    l.get_frame().set_alpha(0.0)\n",
    "    ax.set_title(f\"RGI Region 01 (Alaska): # Glacier Complexes: {n_processed_glaciers}, Area: {ak_processed_area_percent:0.0f}%\",  {\"weight\": \"bold\"})\n",
    "    ax.set_ylabel(\"Cumulative mass change\\nsince 1980 (Gt)\")\n",
    "    ax.set_xlim(\n",
    "        np.datetime64(f\"{x_lim[0]}-01-01\"),\n",
    "        np.datetime64(f\"{x_lim[1]}-01-01\"),\n",
    "    )\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(p / \"all_glaciers.png\", dpi=300, transparent=True)\n",
    "    plt.close()\n",
    "    del fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745a7717-f175-4ae4-8f78-ee1bfeecc175",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", r\"All-NaN (slice|axis) encountered\")\n",
    "    glacier_quantiles = []\n",
    "    for q in percentiles:\n",
    "        glacier_quantiles.append(scalar_ds.quantile(q, dim=\"exp_id\", skipna=True).expand_dims({\"quantile\": [q]}))\n",
    "glacier_quantiles = xr.merge(glacier_quantiles)\n",
    "with mpl.rc_context({\"font.size\": fontsize}):\n",
    "    \n",
    "    for rgi_id, glacier in glacier_quantiles.groupby(\"rgi_id\"):\n",
    "        s = glacier.squeeze()\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(6.4, 3.2))\n",
    "        \n",
    "        glacier_cis = []\n",
    "        \n",
    "        glacier_ci = ax.fill_between(\n",
    "            s.sel({\"quantile\": 0.5}).time,\n",
    "            s.sel({\"quantile\": percentiles[0]})[p_var],\n",
    "            s.sel({\"quantile\": percentiles[-1]})[p_var],\n",
    "            alpha=sim_alpha,\n",
    "            color=sim_cmap[0],\n",
    "            lw=0,\n",
    "            label=f\"{percentile_range_90:.0f}% credibility interval\",\n",
    "        )\n",
    "        glacier_cis.append(glacier_ci)\n",
    "        h  = s.sel({\"quantile\": 0.5})[p_var].plot(\n",
    "            color=sim_cmap[2],\n",
    "            add_legend=False,\n",
    "            ax=ax,\n",
    "            lw=1,\n",
    "            ls=\"solid\",\n",
    "        )\n",
    "        \n",
    "        # limits still apply, even if we hide the axis\n",
    "        ax.set_xlim(\n",
    "            np.datetime64(f\"{x_lim[0]}-01-01\"),\n",
    "            np.datetime64(f\"{x_lim[1]}-01-01\"),\n",
    "        )\n",
    "        \n",
    "        # --- turn EVERYTHING off ---\n",
    "        ax.set_axis_off()  # hides spines, ticks, labels, etc.\n",
    "        ax.set_title(rgi_id)\n",
    "        \n",
    "        # optional: make sure no extra padding around the plot\n",
    "        fig.tight_layout(pad=0)\n",
    "        \n",
    "        fig.savefig(\n",
    "            p / f\"{rgi_id}.png\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",   # crop to content\n",
    "            pad_inches=0,\n",
    "            transparent=True,      # nice for overlaying on slides\n",
    "        )\n",
    "        plt.close(fig)\n",
    "        del fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c55194-532b-4f9d-a74b-351c5535e0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_median = False\n",
    "with mpl.rc_context({\"font.size\": fontsize}):\n",
    "\n",
    "    fig, axs = plt.subplots(3, 1, sharex=True, figsize=figsize)\n",
    "    sim_cis = []\n",
    "\n",
    "    for k, p_var in enumerate([\"mass_balance\", \"surface_mass_balance\", \"ice_discharge\"]):\n",
    "        sim_ci = axs[k].fill_between(\n",
    "            sim_quantiles[0.5].time,\n",
    "            sim_quantiles[percentiles[0]][p_var],\n",
    "            sim_quantiles[percentiles[1]][p_var],\n",
    "            alpha=sim_alpha,\n",
    "            color=sim_cmap[0],\n",
    "            lw=0,\n",
    "            label=f\"\"\"{percentile_range:.0f}% credibility interval\"\"\",\n",
    "        )\n",
    "        sim_cis.append(sim_ci)\n",
    "    \n",
    "    if add_median:\n",
    "        sim_quantiles[percentiles[0]][p_var].plot(\n",
    "            color=sim_cmap[1],\n",
    "            add_legend=False,\n",
    "            ax=ax,\n",
    "            lw=0.25,\n",
    "            ls=\"solid\",\n",
    "        )\n",
    "        h  = sim_quantiles[0.5][p_var].plot(\n",
    "            color=sim_cmap[1],\n",
    "            add_legend=False,\n",
    "            ax=ax,\n",
    "            lw=1,\n",
    "            ls=\"solid\",\n",
    "            label=\"Median\"\n",
    "        )\n",
    "        sim_cis.append(h[0])\n",
    "        sim_quantiles[percentiles[1]][p_var].plot(\n",
    "            color=sim_cmap[1],\n",
    "            add_legend=False,\n",
    "            ax=ax,\n",
    "            lw=0.25,\n",
    "            ls=\"solid\",\n",
    "        )\n",
    "    l = axs[-1].legend(handles=sim_cis, loc=\"lower left\")\n",
    "    l.get_frame().set_linewidth(0.0)\n",
    "    l.get_frame().set_alpha(0.0)\n",
    "    axs[-1].set_ylabel(\"Cumulative mass change\\nsince 1978 (Gt)\")\n",
    "    axs[-1].set_xlim(\n",
    "        np.datetime64(f\"{x_lim[0]}-01-01\"),\n",
    "        np.datetime64(f\"{x_lim[1]}-01-01\"),\n",
    "    )\n",
    "\n",
    "    fig.savefig(p / \"all_glaciers_fluxes.png\", dpi=300, transparent=True)\n",
    "    plt.close()\n",
    "    del fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcfaa65-b447-4ab5-aa41-964449a904c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "larsen_mean = -77\n",
    "larsen_std = 11\n",
    "all_glaciers.sel({\"time\": slice(\"1994\", \"2013\")}).mean(dim=\"time\").mass_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd9ee14-f908-4ec9-b10a-33265ade1c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_rgi = defaultdict(list)\n",
    "\n",
    "for job_id, info in spatial_dict.items():\n",
    "    rgi_id = info[\"rgi_id\"]\n",
    "    url = info[\"url\"]\n",
    "    by_rgi[rgi_id].append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4698e473-207d-4cf5-99eb-423fb6f907a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, progress\n",
    "import xarray as xr\n",
    "\n",
    "client = Client()  # or connect to your scheduler\n",
    "print(f\"Open client in browser: {client.dashboard_link}\")\n",
    "\n",
    "def compute_speed_for_rgi(rgi_id: str, urls: list[str]):\n",
    "    ds = xr.open_mfdataset(\n",
    "        urls,\n",
    "        preprocess=preprocess_config,\n",
    "        parallel=True,\n",
    "        chunks=\"auto\",\n",
    "        engine=\"h5netcdf\",\n",
    "    )\n",
    "    ds = ds.sel(time=slice(\"1980\", \"2025\"))\n",
    "    ds_last = ds.isel(time=-1)\n",
    "    #speed = ds_last[\"velsurf_mag\"].median(dim=\"exp_id\").squeeze()\n",
    "    speed = ds_last.isel({\"exp_id\": -1})\n",
    "    return speed\n",
    "\n",
    "# submit futures\n",
    "futures = {\n",
    "    rgi_id: client.submit(compute_speed_for_rgi, rgi_id, urls)\n",
    "    for rgi_id, urls in by_rgi.items()\n",
    "}\n",
    "\n",
    "# show progress bar for all futures\n",
    "progress(list(futures.values()))\n",
    "\n",
    "# gather results once done\n",
    "results = {rgi_id: fut.result() for rgi_id, fut in futures.items()}\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb9fbb5-e836-4000-9c2d-1641a6199b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_mfdataset(by_rgi[\"RGI2000-v7.0-C-01-09429\"],         \n",
    "                       preprocess=preprocess_config,\n",
    "                       parallel=True,\n",
    "                       chunks=\"auto\",\n",
    "                       engine=\"h5netcdf\",\n",
    "                      )\n",
    "ds = ds.sel(time=slice(\"1980\", \"2025\"))\n",
    "ds_last = ds.isel(time=-1)\n",
    "print(ds_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd72df6-43c6-4b4e-8e59-884012afed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rgi_files = Path(\"/Users/andy/Google Drive/My Drive/data/RGI7/RGI2000-v7/RGI2000-v7-G\").rglob(\"*.shp\")\n",
    "all_rgi = pd.concat([gpd.read_file(f) for f in list(all_rgi_files)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12dcce9-c135-4f0a-9ce2-a193d42d0c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(df, threshold, name):\n",
    "    df = df[df[\"area_km2\"] > threshold]\n",
    "    data = df[\"area_km2\"]\n",
    "    xmin = max(1, np.nanmin(data[data > 0]))\n",
    "    xmax = np.nanmax(data)\n",
    "    lo, hi = np.floor(np.log10(xmin)), np.ceil(np.log10(xmax))\n",
    "    bins = np.logspace(lo, hi, 11)  # 10 edges → 9 bars\n",
    "    \n",
    "    formatter = ScalarFormatter()\n",
    "    formatter.set_scientific(False)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6.4, 3.0))\n",
    "    counts, edges, patches = ax.hist(\n",
    "        data,\n",
    "        bins=bins,\n",
    "        histtype=\"bar\",\n",
    "        rwidth=1.0,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.25,\n",
    "    )\n",
    "    \n",
    "    # ---- color bars: viridis, linear in area (km^2) ----\n",
    "    cmap = mpl.colormaps.get_cmap(\"inferno\")\n",
    "    cmap = cmc.managua_r\n",
    "    norm = colors.LogNorm(vmin=edges[0], vmax=edges[-1])  # linear mapping\n",
    "    \n",
    "    # Representative area per bar (geometric mean matches log-x placement)\n",
    "    centers = np.sqrt(edges[:-1] * edges[1:])\n",
    "    # If you prefer linear midpoints instead: centers = 0.5*(edges[:-1] + edges[1:])\n",
    "    \n",
    "    for p, a in zip(patches, centers):\n",
    "        p.set_facecolor(cmap(norm(a)))\n",
    "    \n",
    "    # Optional colorbar\n",
    "    sm = cm.ScalarMappable(norm=norm, cmap=cmap); sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=ax, pad=0.02, shrink=0.9)\n",
    "    cbar.set_label(\"Area (km²)\")\n",
    "    cbar.ax.yaxis.set_major_formatter(FuncFormatter(lambda x, pos: f\"{int(x):,}\"))\n",
    "\n",
    "    area = sum(data)\n",
    "    ax.set_title(f\"{name}\", {\"weight\": \"bold\"})\n",
    "    # Axes styling\n",
    "    ax.set_xscale(\"log\"); ax.set_yscale(\"log\")\n",
    "    ax.set_xticks([1, 10, 100, 1000, 10000, 100000])\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    ax.yaxis.set_major_formatter(formatter)\n",
    "    ax.set_xlim([1, 100_000])\n",
    "    ax.set_xlabel(\"Area (km$^{2}$)\")\n",
    "    ax.set_ylabel(\"Count (1)\")\n",
    "    for side in (\"top\", \"right\"):\n",
    "        ax.spines[side].set_visible(False)\n",
    "    ax.tick_params(top=False, right=False)\n",
    "    \n",
    "    # # (Optional) annotate counts:\n",
    "    # for c, rect in zip(counts, patches):\n",
    "    #     if c <= 0: continue\n",
    "    #     x = rect.get_x() + rect.get_width()/2\n",
    "    #     ax.annotate(f\"{int(c):,}\", (x, c),\n",
    "    #                 xytext=(0, 4), textcoords=\"offset points\",\n",
    "    #                 ha=\"center\", va=\"bottom\", clip_on=False)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "    \n",
    "\n",
    "threshold = 0.001\n",
    "fontsize = 12\n",
    "rcparams_white = {\n",
    "    \"axes.linewidth\": 0.75,\n",
    "    \"axes.edgecolor\": \"white\",\n",
    "    \"xtick.major.size\": 2.0,\n",
    "    \"xtick.major.width\": 0.5,\n",
    "    \"ytick.major.size\": 2.0,\n",
    "    \"ytick.major.width\": 0.5,\n",
    "    \"hatch.linewidth\": 0.5,\n",
    "    'font.weight': \"bold\",\n",
    "    \"font.size\": fontsize,\n",
    "    'axes.labelweight': \"bold\",\n",
    "    'text.color': \"white\",\n",
    "    'axes.labelcolor': \"white\",\n",
    "    'xtick.color': \"white\",\n",
    "    'ytick.color': \"white\",\n",
    "}\n",
    "p = Path(\"/Users/andy/Google Drive/My Drive/Projects/terra/figures/\")\n",
    "\n",
    "\n",
    "with mpl.rc_context(rcparams_white):\n",
    "    fig = plot_hist(all_rgi, threshold, \"Size\")\n",
    "    fig.savefig(p / \"rgi_size_distribution.png\", dpi=300, transparent=True)\n",
    "plt.close()\n",
    "del fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdf392d-9a35-4a71-bf77-8bee29361a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcparams_white_pie =rcparams_white.copy()\n",
    "rcparams_white_pie.update({\"font.size\": 20})\n",
    "with mpl.rc_context(rcparams_white_pie):\n",
    "\n",
    "    fig = all_rgi.groupby('o1region')[\"area_km2\"].sum().plot(kind='pie', cmap=cmc.managua_r.resampled(20),\n",
    "                                                             y=\"Region\", figsize=(6.4, 6.4),\n",
    "                                                   explode=np.zeros(17) + 0.15)\n",
    "    fig.set_title(\"Area by Region\", {\"weight\": \"bold\"})\n",
    "    fig.figure.tight_layout()\n",
    "    fig.figure.savefig(p / \"rgi_regions.png\", dpi=300, transparent=True)\n",
    "plt.close()\n",
    "del fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c52f6d7-3c1e-4f9b-9c18-4883d0b02c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1b12fa-2870-42f0-ac78-0d091842eb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "slc_df = pd.Series({\"Antarctica\": 20, \"Glaciers\":30, \"Greenland\": 37, \"Other\": 13}, index=[\"Antarctica\", \"Glaciers\", \"Greenland\", \"Other\"])\n",
    "with mpl.rc_context(rcparams_white_pie):\n",
    "    fig = slc_df.plot(kind='pie', cmap=cmc.managua_r.resampled(4),\n",
    "                                                             figsize=(6.4, 6.4), autopct=\"%.0f\",                                                                                                                            \n",
    "                                                   explode=[0, 0.1, 0, 0])\n",
    "    fig.set_title(\"Sea-level contribution\", {\"weight\": \"bold\"})\n",
    "    fig.figure.tight_layout()\n",
    "    fig.figure.savefig(p / \"sea-level-contribution.png\", dpi=300, transparent=True)\n",
    "plt.close()\n",
    "del fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992888a1-b8a5-49b0-bbbd-9e3151463568",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ccba00-6c6f-4e8c-96c1-b7789bead4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "from dask.distributed import Client, progress\n",
    "\n",
    "speed_bins = np.logspace(-1, 4, 6)\n",
    "\n",
    "client = Client()  # or connect to your scheduler\n",
    "print(f\"Open client in browser: {client.dashboard_link}\")\n",
    "\n",
    "def binned_counts_for_region(region: str, speed_bins: np.ndarray):\n",
    "    \"\"\"\n",
    "    Open ITS_LIVE velocity COG for one RGI region,\n",
    "    bin speeds, and return counts per speed bin.\n",
    "    Returns a *computed* 1D DataArray or None if failed.\n",
    "    \"\"\"\n",
    "    url = (\n",
    "        f\"https://its-live-data.s3.amazonaws.com/velocity_mosaic/v2/static/cog/\"\n",
    "        f\"ITS_LIVE_velocity_120m_RGI{region}A_0000_v02_v.tif\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        da = rxr.open_rasterio(url, chunks=\"auto\").squeeze()  # (y, x)\n",
    "    except Exception:\n",
    "        # e.g. missing file; just skip this region\n",
    "        return None\n",
    "\n",
    "    # mask low speeds\n",
    "    da = da.where(da > 0.1)\n",
    "\n",
    "    # histogram binning: group by the DataArray itself\n",
    "    binned = da.groupby_bins(da, bins=speed_bins).count()\n",
    "\n",
    "    # compute here so the future returns a small, in-memory DataArray\n",
    "    return binned.compute()\n",
    "\n",
    "\n",
    "# --- submit one future per region ---\n",
    "regions = list(rgi[\"o1region\"].unique())\n",
    "\n",
    "futures = {\n",
    "    region: client.submit(binned_counts_for_region, region, speed_bins)\n",
    "    for region in regions\n",
    "}\n",
    "\n",
    "# progress bar for all futures\n",
    "progress(list(futures.values()))\n",
    "\n",
    "# collect results, skipping failures (None)\n",
    "binned_list = []\n",
    "for region, fut in futures.items():\n",
    "    res = fut.result()\n",
    "    if res is not None:\n",
    "        binned_list.append(res)\n",
    "\n",
    "if binned_list:\n",
    "    # safer than pairwise +: aligns on speed_bins coordinate\n",
    "    total_binned = xr.concat(binned_list, dim=\"region\").sum(\"region\")\n",
    "else:\n",
    "    total_binned = None\n",
    "\n",
    "print(total_binned)\n",
    "\n",
    "client.cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a13608-814f-4454-b841-18de7d38460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://its-live-data.s3.amazonaws.com/velocity_mosaic/v2/static/cog/ITS_LIVE_velocity_120m_RGI01A_0000_v02_v.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e388e79-317a-4ba4-bfb5-6ada32ff9629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_speed_hist(da, bins, name):\n",
    "    \n",
    "    data = da.values          # shape (N,)\n",
    "    counts = da.values\n",
    "    bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "    data = np.repeat(bin_centers, counts.astype(int))    \n",
    "    formatter = ScalarFormatter()\n",
    "    formatter.set_scientific(False)\n",
    "    \n",
    "    total = data.size\n",
    "    weights = np.ones_like(data) / total * 100.0  # each sample = this many percent\n",
    "\n",
    "    formatter = ScalarFormatter()\n",
    "    formatter.set_scientific(False)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6.4, 3.0))\n",
    "    counts, edges, patches = ax.hist(\n",
    "        data,\n",
    "        bins=bins,\n",
    "        weights=weights,        # <-- key line\n",
    "        histtype=\"bar\",\n",
    "        rwidth=1.0,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.25,\n",
    "    )\n",
    "    \n",
    "    # ---- color bars: viridis, linear in area (km^2) ----\n",
    "    cmap = mpl.colormaps.get_cmap(\"inferno\")\n",
    "    cmap = cmc.managua_r\n",
    "    norm = colors.LogNorm(vmin=edges[0], vmax=edges[-1])  # linear mapping\n",
    "    \n",
    "    # Representative area per bar (geometric mean matches log-x placement)\n",
    "    centers = np.sqrt(edges[:-1] * edges[1:])\n",
    "    # If you prefer linear midpoints instead: centers = 0.5*(edges[:-1] + edges[1:])\n",
    "    \n",
    "    for p, a in zip(patches, centers):\n",
    "        p.set_facecolor(cmap(norm(a)))\n",
    "    \n",
    "    # Optional colorbar\n",
    "    sm = cm.ScalarMappable(norm=norm, cmap=cmap); sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=ax, pad=0.02, shrink=0.9)\n",
    "    cbar.set_label(\"Speed (m yr$^{-2}$)\")\n",
    "    cbar.ax.yaxis.set_major_formatter(FuncFormatter(lambda x, pos: f\"{int(x):,}\"))\n",
    "\n",
    "    ax.set_title(f\"{name}\", {\"weight\": \"bold\"})\n",
    "    # Axes styling\n",
    "    ax.set_xscale(\"log\"); \n",
    "    ax.set_xticks([1, 10, 100, 1000, 10000, 100000])\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    ax.yaxis.set_major_formatter(formatter)\n",
    "    #ax.set_xlim([1, 100_000])\n",
    "    ax.set_xlabel(\"Speed (m yr$^{-2}$)\")\n",
    "    ax.set_ylabel(\"Percentage (%)\")\n",
    "    for side in (\"top\", \"right\"):\n",
    "        ax.spines[side].set_visible(False)\n",
    "    ax.tick_params(top=False, right=False)\n",
    "    \n",
    "    \n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "    \n",
    "\n",
    "threshold = 0.001\n",
    "fontsize = 12\n",
    "rcparams_white = {\n",
    "    \"axes.linewidth\": 0.75,\n",
    "    \"axes.edgecolor\": \"white\",\n",
    "    \"xtick.major.size\": 2.0,\n",
    "    \"xtick.major.width\": 0.5,\n",
    "    \"ytick.major.size\": 2.0,\n",
    "    \"ytick.major.width\": 0.5,\n",
    "    \"hatch.linewidth\": 0.5,\n",
    "    'font.weight': \"bold\",\n",
    "    \"font.size\": fontsize,\n",
    "    'axes.labelweight': \"bold\",\n",
    "    'text.color': \"white\",\n",
    "    'axes.labelcolor': \"white\",\n",
    "    'xtick.color': \"white\",\n",
    "    'ytick.color': \"white\",\n",
    "}\n",
    "p = Path(\"/Users/andy/Google Drive/My Drive/Projects/terra/figures/\")\n",
    "\n",
    "\n",
    "with mpl.rc_context(rcparams_white):\n",
    "    fig = plot_speed_hist(total_binned, speed_bins, \"Speeds\")\n",
    "    fig.savefig(p / \"rgi_speed_distribution.png\", dpi=300, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344c936b-7446-4d4a-8908-60b7bcf714ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= all_rgi.groupby('o1region')[\"area_km2\"].sum()\n",
    "df.plot.pie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44497b49-14b1-4b6a-85f5-05de8132b19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series({\"Antarctica\": 20, \"Glaciers\":30, \"Greenland\": 37}, index=[\"Antarctica\", \"Glaciers\", \"Greenland\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41b774a-3d14-47b6-a501-536cfd28697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0192ab7-8987-4726-a956-6c75cb5db18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_processed_glaciers = len(processed_glaciers_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a948fe-67ac-4b12-9768-5311f493d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit\n",
    "from dask.distributed import Client, progress\n",
    "import s3fs\n",
    "from pathlib import Path\n",
    "\n",
    "client = Client()  # or connect to your scheduler\n",
    "print(f\"Open client in browser: {client.dashboard_link}\")\n",
    "\n",
    "def pick(files, pattern):\n",
    "    for f in files:\n",
    "        if pattern in Path(f).name:\n",
    "            return f\n",
    "    return None\n",
    "\n",
    "def list_and_pick(job_id, s3_id, rgi_id, anon=True):\n",
    "    \"\"\"\n",
    "    List prefix on S3 and pick scalar + spatial files.\n",
    "    Returns (job_id, scalar_dict_or_None, spatial_dict_or_None).\n",
    "    \"\"\"\n",
    "    fs = s3fs.S3FileSystem(anon=anon)  # make a fresh FS on the worker\n",
    "    prefix = f\"{s3_id}/{rgi_id}/output/spatial/\"\n",
    "    files = fs.ls(prefix)\n",
    "\n",
    "    spatial_file = pick(files, \"clipped_spatial_\")\n",
    "    scalar_file  = pick(files, \"fldsum_spatial_\")\n",
    "\n",
    "    scalar_entry = None\n",
    "    spatial_entry = None\n",
    "\n",
    "    if scalar_file is not None:\n",
    "        scalar_entry = {\"rgi_id\": rgi_id, \"url\": f\"s3://{scalar_file}\"}\n",
    "    if spatial_file is not None:\n",
    "        spatial_entry = {\"rgi_id\": rgi_id, \"url\": f\"s3://{spatial_file}\"}\n",
    "\n",
    "    return job_id, scalar_entry, spatial_entry\n",
    "\n",
    "\n",
    "# ---- submit tasks ----\n",
    "futures = []\n",
    "for job_id, meta in s3_ids.items():\n",
    "    futures.append(\n",
    "        client.submit(list_and_pick, job_id, meta[\"s3_id\"], meta[\"rgi_id\"], True)\n",
    "    )\n",
    "\n",
    "progress(futures)\n",
    "\n",
    "# ---- gather and assemble ----\n",
    "scalar_dict = {}\n",
    "spatial_dict = {}\n",
    "\n",
    "for job_id, scalar_entry, spatial_entry in client.gather(futures):\n",
    "    if scalar_entry is not None:\n",
    "        scalar_dict[job_id] = scalar_entry\n",
    "    if spatial_entry is not None:\n",
    "        spatial_dict[job_id] = spatial_entry\n",
    "\n",
    "scalar_files  = [v[\"url\"] for v in scalar_dict.values()]\n",
    "spatial_files = [v[\"url\"] for v in spatial_dict.values()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a43ada-84d5-4b01-bd90-190a9fc8f92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26bd2c2-a5d0-4bc3-8df7-0a8a5d67eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdk.HyP3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fba13b-d231-451f-8a07-0783947fa104",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgi = gpd.read_file(\"s3://pism-cloud-data/terra/rgi.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506ece69-ee28-4cee-9180-92f9a74a1558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pint_xarray\n",
    "import rioxarray\n",
    "obs = xr.open_dataset(\"/Users/andy/Downloads/GreenlandObsISMIP7-v1.3.nc\", chunks=\"auto\")\n",
    "obs.pint.quantify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9eb099-1361-4c45-9161-18dae4fffb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import pyogrio\n",
    "from io import BytesIO\n",
    "\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "with fs.open(\"s3://pism-cloud-data/terra/rgi.gpkg\", \"rb\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "rgi = pyogrio.read_dataframe(BytesIO(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eecece-2a94-4fdb-93aa-c012ebc8b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import pyogrio\n",
    "from io import BytesIO\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "fs = s3fs.S3FileSystem(anon=True)  # True if public\n",
    "\n",
    "s3_url = \"s3://pism-cloud-data/terra/rgi.gpkg\"\n",
    "\n",
    "# Get file size for tqdm (falls back gracefully if not available)\n",
    "size = None\n",
    "try:\n",
    "    size = fs.size(s3_url)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "buf = bytearray()\n",
    "with fs.open(s3_url, \"rb\") as f:\n",
    "    with tqdm(total=size, unit=\"B\", unit_scale=True, unit_divisor=1024, desc=\"Downloading rgi.gpkg\") as pbar:\n",
    "        for chunk in iter(lambda: f.read(8 * 1024 * 1024), b\"\"):  # 8 MiB chunks\n",
    "            buf.extend(chunk)\n",
    "            pbar.update(len(chunk))\n",
    "\n",
    "rgi = pyogrio.read_dataframe(BytesIO(buf))\n",
    "rgi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33e3b14-4dc2-4180-97fd-113045eb24d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import pyogrio\n",
    "from io import BytesIO\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efaf16e-656a-4f8e-86a9-1a7b4a7e5d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3fs.S3FileSystem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d034f09c-ef4d-4626-b83f-8dd35117c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dss = []\n",
    "for k, skip in zip([0, 1, 2, 3], [50, 100, 250, 1000]):\n",
    "    p = f\"/Users/andy/base/pism-terra/2025_11_wrangell_ho/RGI2000-v7.0-C-01-04374/output/state/state_g500m_RGI2000-v7.0-C-01-04374_id_{k}_01-01-01_02-01-01.nc\"\n",
    "    try:\n",
    "        ds = xr.open_dataset(p, decode_times=False)\n",
    "        ds = ds.expand_dims(skip=[skip])\n",
    "        dss.append(ds)\n",
    "    except:\n",
    "        pass\n",
    "ds = xr.merge(dss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57c0e52-5bf0-4e56-9d75-9f5e40c1abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.wall_clock_time * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1792fa0-c69e-4f9f-894f-d36a46abcf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.velsurf_mag.plot(col=\"skip\", vmax=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4c282b-ded7-4c82-acf5-da0ddbe3dd1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
